{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K0IWuMv1lOar"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import json\n",
    "import joblib\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sGOsQ6M1lXBi"
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (8, 8)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22917,
     "status": "ok",
     "timestamp": 1655401990413,
     "user": {
      "displayName": "Владимир Леонидович Дидковский",
      "userId": "04739395853249047201"
     },
     "user_tz": -180
    },
    "id": "v6QZ4Argqf2S",
    "outputId": "c8a476f3-1d6f-4833-cb5c-e308f572a4ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# # Подключение данных гугл диска\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nS7_ON8mJJx"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://quaterion.qdrant.tech/tutorials/cars-tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pytorch_lightning==1.2.2\n",
      "  Downloading pytorch_lightning-1.2.2-py3-none-any.whl (816 kB)\n",
      "\u001b[K     |████████████████████████████████| 816 kB 14.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.2) (1.11.0+cu113)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.2) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.2) (1.21.6)\n",
      "Collecting PyYAML!=5.4.*,>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 68.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.2) (2.8.0)\n",
      "Collecting fsspec[http]>=0.8.1\n",
      "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 71.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future>=0.17.1\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 61.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 64.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning==1.2.2) (2.23.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.2) (1.35.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.2) (3.17.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.2) (57.4.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.2) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.2) (1.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.2) (1.0.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.2) (1.46.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.2) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.2) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.2) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.2.2) (1.8.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.2) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.2) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.2) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.2) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.2.2) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.2.2) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.2.2) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.2.2) (4.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.2.2) (0.4.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning==1.2.2) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning==1.2.2) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning==1.2.2) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning==1.2.2) (2022.6.15)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.2.2) (3.2.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 75.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[K     |████████████████████████████████| 144 kB 74.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.2.2) (2.0.12)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.2.2) (21.4.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 3.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=f549483a96b1010c5b187a0170aa39637f70ae9010b7e82bf0c0002bc2423d79\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "Successfully built future\n",
      "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, PyYAML, future, pytorch-lightning\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: future\n",
      "    Found existing installation: future 0.16.0\n",
      "    Uninstalling future-0.16.0:\n",
      "      Successfully uninstalled future-0.16.0\n",
      "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.5.0 future-0.18.2 multidict-6.0.2 pytorch-lightning-1.2.2 yarl-1.7.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting quaterion==0.1.23\n",
      "  Downloading quaterion-0.1.23-py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 5.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting mmh3<4.0.0,>=3.0.0\n",
      "  Downloading mmh3-3.0.0-cp37-cp37m-manylinux2010_x86_64.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 9.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from quaterion==0.1.23) (1.11.0+cu113)\n",
      "Collecting quaterion-models>=0.1.9\n",
      "  Downloading quaterion_models-0.1.9-py3-none-any.whl (17 kB)\n",
      "Collecting rich<13.0.0,>=12.4.4\n",
      "  Downloading rich-12.4.4-py3-none-any.whl (232 kB)\n",
      "\u001b[K     |████████████████████████████████| 232 kB 33.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchmetrics<=0.8.2\n",
      "  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n",
      "\u001b[K     |████████████████████████████████| 409 kB 61.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytorch-lightning<2.0.0,>=1.6.4\n",
      "  Downloading pytorch_lightning-1.6.4-py3-none-any.whl (585 kB)\n",
      "\u001b[K     |████████████████████████████████| 585 kB 59.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from quaterion==0.1.23) (3.17.3)\n",
      "Collecting loguru<0.6.0,>=0.5.3\n",
      "  Downloading loguru-0.5.3-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 6.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<3.20,>=3.9.2->quaterion==0.1.23) (1.15.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (4.64.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (21.3)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (2022.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (4.1.1)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (1.21.6)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (6.0)\n",
      "Collecting pyDeprecate>=0.3.1\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (2.23.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (3.0.9)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 9.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich<13.0.0,>=12.4.4->quaterion==0.1.23) (2.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (1.1.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (1.8.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (1.46.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (57.4.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (3.3.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (1.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (0.4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (2022.6.15)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (3.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (4.0.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (0.13.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.6.4->quaterion==0.1.23) (2.0.12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: pyDeprecate, torchmetrics, commonmark, rich, quaterion-models, pytorch-lightning, mmh3, loguru, quaterion\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.2.2\n",
      "    Uninstalling pytorch-lightning-1.2.2:\n",
      "      Successfully uninstalled pytorch-lightning-1.2.2\n",
      "Successfully installed commonmark-0.9.1 loguru-0.5.3 mmh3-3.0.0 pyDeprecate-0.3.2 pytorch-lightning-1.6.4 quaterion-0.1.23 quaterion-models-0.1.9 rich-12.4.4 torchmetrics-0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_lightning==1.2.2\n",
    "!pip install quaterion==0.1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from typing import Callable\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "from quaterion.dataset import (\n",
    "    GroupSimilarityDataLoader,\n",
    "    SimilarityGroupSample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XO-KWj29Eq-g"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# set seed to deterministically sample train and test categories later on\n",
    "seed_everything(seed=42)\n",
    "\n",
    "# dataset will be downloaded to this directory under local directory\n",
    "dataset_path = os.path.join(\".\", \"torchvision\", \"datasets\")\n",
    "\n",
    "\n",
    "class CarsDataset(Dataset):\n",
    "    def __init__(self, dataset: Dataset, transform: Callable):\n",
    "        self._dataset = dataset\n",
    "        self._transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._dataset)\n",
    "\n",
    "    def __getitem__(self, index) -> SimilarityGroupSample:\n",
    "        image, label = self._dataset[index]\n",
    "        image = self._transform(image)\n",
    "\n",
    "        return SimilarityGroupSample(obj=image, group=label)\n",
    "\n",
    "\n",
    "def get_datasets(input_size: int):\n",
    "    # Use Mean and std values for the ImageNet dataset as the base model was pretrained on it.\n",
    "    # taken from https://www.geeksforgeeks.org/how-to-normalize-images-in-pytorch/\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # create train and test transforms\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # we need to merge train and test splits into a full dataset first,\n",
    "    # and then we will split it to two subsets again with each one composed of distinct labels.\n",
    "    full_dataset = datasets.StanfordCars(\n",
    "        root=dataset_path, split=\"train\", download=True\n",
    "    ) + datasets.StanfordCars(root=dataset_path, split=\"test\", download=True)\n",
    "\n",
    "    # full_dataset contains examples from 196 categories labeled with an integer from 0 to 195\n",
    "    # randomly sample half of it to be used for training\n",
    "    train_categories = np.random.choice(a=196, size=196 // 2, replace=False)\n",
    "\n",
    "    # get a list of labels for all samples in the dataset\n",
    "    labels_list = np.array([label for _, label in tqdm.tqdm(full_dataset)])\n",
    "\n",
    "    # get a mask for indices where label is included in train_categories\n",
    "    labels_mask = np.isin(labels_list, train_categories)\n",
    "\n",
    "    # get a list of indices to be used as train samples\n",
    "    train_indices = np.argwhere(labels_mask).squeeze()\n",
    "\n",
    "    # others will be used as test samples\n",
    "    test_indices = np.argwhere(np.logical_not(labels_mask)).squeeze()\n",
    "\n",
    "    # now that we have distinct indices for train and test sets, we can use `Subset` to create new datasets\n",
    "    # from `full_dataset`, which contain only the samples at given indices.\n",
    "    # finally, we apply transformations created above.\n",
    "    train_dataset = CarsDataset(\n",
    "        Subset(full_dataset, train_indices), transform=transform\n",
    "    )\n",
    "\n",
    "    test_dataset = CarsDataset(\n",
    "        Subset(full_dataset, test_indices), transform=transform\n",
    "    )\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "def get_dataloaders(\n",
    "    batch_size: int,\n",
    "    input_size: int,\n",
    "    shuffle: bool = False,\n",
    "):\n",
    "    train_dataset, test_dataset = get_datasets(input_size)\n",
    "\n",
    "    train_dataloader = GroupSimilarityDataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    test_dataloader = GroupSimilarityDataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HOWyo530Eq3a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from quaterion_models.encoders import Encoder\n",
    "from quaterion_models.heads import EncoderHead, SkipConnectionHead\n",
    "from torch import nn\n",
    "from typing import Dict, Union, Optional, List\n",
    "\n",
    "from quaterion import TrainableModel\n",
    "from quaterion.eval.attached_metric import AttachedMetric\n",
    "from quaterion.eval.group import RetrievalRPrecision\n",
    "from quaterion.loss import SimilarityLoss, TripletLoss\n",
    "from quaterion.train.cache import CacheConfig, CacheType\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from quaterion_models.encoders import Encoder\n",
    "\n",
    "\n",
    "class CarsEncoder(Encoder):\n",
    "    def __init__(self, encoder_model: nn.Module):\n",
    "        super().__init__()\n",
    "        self._encoder = encoder_model\n",
    "        self._embedding_size = 2048  # last dimension from the ResNet model\n",
    "\n",
    "    @property\n",
    "    def trainable(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def embedding_size(self) -> int:\n",
    "        return self._embedding_size\n",
    "\n",
    "    def forward(self, images):\n",
    "        embeddings = self._encoder.forward(images)\n",
    "        return embeddings\n",
    "\n",
    "    def save(self, output_path: str):\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        torch.save(self._encoder, os.path.join(output_path, \"encoder.pth\"))\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, input_path):\n",
    "        encoder_model = torch.load(os.path.join(input_path, \"encoder.pth\"))\n",
    "        return CarsEncoder(encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9lCUAjquEqte"
   },
   "outputs": [],
   "source": [
    "class Model(TrainableModel):\n",
    "    def __init__(self, lr: float, mining: str):\n",
    "        self._lr = lr\n",
    "        self._mining = mining\n",
    "        super().__init__()\n",
    "\n",
    "    def configure_encoders(self) -> Union[Encoder, Dict[str, Encoder]]:\n",
    "        pre_trained_encoder = torchvision.models.resnet152(pretrained=True)\n",
    "        pre_trained_encoder.fc = nn.Identity()\n",
    "        return CarsEncoder(pre_trained_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MwZ8XAx3_z5d"
   },
   "outputs": [],
   "source": [
    "def configure_head(self, input_embedding_size) -> EncoderHead:\n",
    "    return SkipConnectionHead(input_embedding_size, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UNydEOM25v3I"
   },
   "outputs": [],
   "source": [
    "def configure_loss(self) -> SimilarityLoss:\n",
    "    return TripletLoss(mining=self._mining, margin=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizers(self):\n",
    "    optimizer = torch.optim.Adam(self.model.parameters(), self._lr)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_caches(self) -> Optional[CacheConfig]:\n",
    "    return CacheConfig(\n",
    "        cache_type=CacheType.AUTO, save_dir=\"./cache_dir\", batch_size=32\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_metrics(self) -> Union[AttachedMetric, List[AttachedMetric]]:\n",
    "    return AttachedMetric(\n",
    "        \"rrp\",\n",
    "        metric=RetrievalRPrecision(),\n",
    "        prog_bar=True,\n",
    "        on_epoch=True,\n",
    "        on_step=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from quaterion_models.encoders import Encoder\n",
    "\n",
    "\n",
    "class CarsEncoder(Encoder):\n",
    "    def __init__(self, encoder_model: nn.Module):\n",
    "        super().__init__()\n",
    "        self._encoder = encoder_model\n",
    "        self._embedding_size = 2048  # last dimension from the ResNet model\n",
    "\n",
    "    @property\n",
    "    def trainable(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def embedding_size(self) -> int:\n",
    "        return self._embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, images):\n",
    "    embeddings = self._encoder.forward(images)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(self, output_path: str):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    torch.save(self._encoder, os.path.join(output_path, \"encoder.pth\"))\n",
    "\n",
    "@classmethod\n",
    "def load(cls, input_path):\n",
    "    encoder_model = torch.load(os.path.join(input_path, \"encoder.pth\"))\n",
    "    return CarsEncoder(encoder_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from typing import Dict, Union\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from quaterion import Quaterion, TrainableModel\n",
    "from quaterion.dataset import (\n",
    "    GroupSimilarityDataLoader,\n",
    "    SimilarityGroupDataset,\n",
    ")\n",
    "from quaterion.loss import (\n",
    "    OnlineContrastiveLoss,\n",
    "    TripletLoss,\n",
    "    SimilarityLoss,\n",
    ")\n",
    "from quaterion_models.heads import EmptyHead, EncoderHead\n",
    "from quaterion_models.encoders import Encoder\n",
    "\n",
    "\n",
    "try:\n",
    "    import torchvision\n",
    "    import torchvision.datasets as datasets\n",
    "    import torchvision.transforms as transforms\n",
    "except ImportError:\n",
    "    import sys\n",
    "\n",
    "    print(\"You need to install torchvision for this example\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "def get_dataloader():\n",
    "    # Use Mean and std values for the ImageNet dataset as the base model was pretrained on it.\n",
    "    # taken from https://www.geeksforgeeks.org/how-to-normalize-images-in-pytorch/\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    path = os.path.join(os.path.expanduser(\"~\"), \"torchvision\", \"datasets\")\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dataset = SimilarityGroupDataset(\n",
    "        datasets.CIFAR100(root=path, download=True, transform=transform)\n",
    "    )\n",
    "    dataloader = GroupSimilarityDataLoader(dataset, batch_size=128, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "class MobilenetV3Encoder(Encoder):\n",
    "    def __init__(self, embedding_size: int):\n",
    "        super().__init__()\n",
    "        self.encoder = torchvision.models.mobilenet_v3_small(pretrained=True)\n",
    "        self.encoder.classifier = nn.Sequential(nn.Linear(576, embedding_size))\n",
    "\n",
    "        self._embedding_size = embedding_size\n",
    "\n",
    "    @property\n",
    "    def trainable(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def embedding_size(self) -> int:\n",
    "        return self._embedding_size\n",
    "\n",
    "    def forward(self, images):\n",
    "        return self.encoder.forward(images)\n",
    "\n",
    "\n",
    "class Model(TrainableModel):\n",
    "    def __init__(self, embedding_size: int, lr: float, loss_fn: str, mining: str):\n",
    "        self._embedding_size = embedding_size\n",
    "        self._lr = lr\n",
    "        self._loss_fn = loss_fn\n",
    "        self._mining = mining\n",
    "        super().__init__()\n",
    "\n",
    "    def configure_encoders(self) -> Union[Encoder, Dict[str, Encoder]]:\n",
    "        return MobilenetV3Encoder(self._embedding_size)\n",
    "\n",
    "    def configure_head(self, input_embedding_size) -> EncoderHead:\n",
    "        return EmptyHead(input_embedding_size)\n",
    "\n",
    "    def configure_loss(self) -> SimilarityLoss:\n",
    "        return (\n",
    "            OnlineContrastiveLoss(mining=self._mining)\n",
    "            if self._loss_fn == \"contrastive\"\n",
    "            else TripletLoss(mining=self._mining)\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), self._lr)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c308c1ac99b242378a681637d0883432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/9.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /root/torchvision/datasets/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be433b21c49f4bc2bbf80b024d6d088e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169001437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/torchvision/datasets/cifar-100-python.tar.gz to /root/torchvision/datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "Missing logger folder: /content/drive/MyDrive/colab_examples/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type                  | Params\n",
      "-------------------------------------------------\n",
      "0 | _model | SimilarityModel       | 1.0 M \n",
      "1 | _loss  | OnlineContrastiveLoss | 0     \n",
      "-------------------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6dd0e61e774ca7a7c2f5ec2e21bda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "lr = 1e-4\n",
    "loss_fn = 'contrastive'\n",
    "mining = 'hard'\n",
    "\n",
    "model = Model(\n",
    "    embedding_size=embedding_size,\n",
    "    lr=lr,\n",
    "    loss_fn=loss_fn,\n",
    "    mining=mining,\n",
    ")\n",
    "\n",
    "train_dataloader = get_dataloader()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1 if torch.cuda.is_available() else 0, num_nodes=1, max_epochs=10\n",
    ")\n",
    "\n",
    "Quaterion.fit(\n",
    "    trainable_model=model,\n",
    "    trainer=trainer,\n",
    "    train_dataloader=train_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tmp_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
